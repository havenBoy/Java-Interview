SPL  （管道式查询语言）

它是一种自研的搜索语言，前期设计可以兼容大多数的OLAP组件。如ES、CK、doris等

目前的状态为，只是支持了Es组件，其他组件暂未支持

应用方面：检索中心与BI大屏模块

主要的作用：

使用简单的搜索查询语言可以对存储介质中的数据进行检索，其中包含简单的过滤，聚合关键等操作

体现了数据即价值的理念

BI大屏，主要通过拖拽计算的维度的方式来达到聚合操作的目的，使得数据可清晰展示用户，方便决策

主要语法关键字：

search/fliter/sort/limit/page/top

主要的约束：

所有的关键字应该以|字符分割，代表一个关键字的执行

有且只有一个search， search关键字后可支持多集群，支持集群下单个索引或多个索引的查询

其他的关键字只能在一个语句中出现一次，除了filter可以多次出现

检索中心主要实现流程：

1. 用户填写spl语句，形如 search cluster.index | filter filed1='1' | agg count(name)  as p | field name,sex | sort score | top name:10

2. 后台通过查询集群名称对应的集群地址拼接，以及查询的spl语句构建一个查询对象，如果Es集群包含认证，需要传入用户密码信息

3. 根据创建的查询对象（集群地址+spl语句）对当前的spl语句内容进行校验，比如关键字的数量，关键字的位置等

4. 通过校验后，真正发起一次Es的请求，引擎侧返回Es请求的原生信息，后台提供处理，展示给前端。

5. 比较重要的是，如何通过一个spl语句构造一个Es的请求。

6. 这里需要用到Antlr4,一款基于java开发的开源语法分析器生成工具，通过定义g4文件，来生成定制的文法规则，从而达到解析语法的作用

7. 通过解析语句，可以获得一个AST（抽象语法树）

8. 怎么构建Es查询的结构，这里以top为例， top的语法为 name:10 那么  "terms":{"field":"name","size":"10","order": {"_count": "desc"}}

9. 又如field关键字，语义为根据给出的字段进行返回数据，没有声明的字段不需要进行返回，field语法为field name, sex, -picture_url

   那么查询的请求体中有"_source": {"include": [ "name", "sex"], "exclude": ["picture_url" ] }，这里也支持反取，在exclude中，声明即可

10. 这样完成了一个完整的Es请求过程

11. 界面上的柱状图的展示以及关于某个字段top10数据的统计，都是通过构造相应的spl语句，单独发起请求，后经过后台加工用于展示的

12. BI模块的功能点类似于数据柱状图的展示，后台通过获取用户拖拽的X轴与Y轴的数据来拼接SPL语句进行查询

13. X轴的值一般为当前索引的字段，Y轴一般为某些字段的聚合数据，展示出某些字段与某些字段的关联信息，业务数据上展示更加直观

数据量大问题的解决：

1. 随着业务的增加，每日新增数据量为1T（真实的数据量），如果是单个索引的查询，会出现查询卡顿
2. 有时甚至将Es的master节点打挂掉，Es的master节点负责查询任务的计划与统筹，当返回的数据量大于JVM的最大值时，会崩溃
2. 
3. 对索引的数据进行切分，类似于分表的概念，例如客户1，客户2，在索引名称上都以某个索引名称开头，后缀会有所不同
4. 使用索引模板，设计出当前索引的字段作为一个模板，后续所有以某个索引前缀开头的索引都遵循此字段约束标准
5. 在写入数据方面，业务上会判断出当前的用户名称，首先判断索引是否存在，不存在则创建后，在写入
6. 在数据读取方面，依然支持以模板方式的全量数据查询，但本身的查询语句中，系统会自动添加page关键字来限制返回数据量
7. 其他方面，会优先建议操作者添加某些用户条件，已达到快速查询的目的

aBDI studio 简单介绍

aBDI  Studio是一个高效、易用的一站式大数据智能分析平台，使用低代码大数据分析模式，围绕数据集成、业务日志分析、数据仓库建设等大数据分析场景，从而加速业务的创新，激发数据的价值。



在大数据底层环境搭建方面，我们使用ambari开源项目，使用Excel模板的方式，完成组件的自定义编排并生成blueprint，可实现一键化安装部署大数据集群，并且基于ambari我们做了二次开发，实现自定义组件的可插拔以及运维，后续为studio平台的构建奠定基础。

集群安装部署方面：以ambari为底座，二次开发，集成其他自定义组件，并进行运行维护

数据集成方面：

数据源+实时采集+cdc同步+离线同步

1. 关系型数据库 （mysql  +  SQLserver + postgresql + orcle ）
2. 大数据存储 （hive + hbase + dipper + ck + redis + MongoDB）
3. 半结构化存储（HDFS + kafka）
4. 时序数据库（openTSDB + InfluxDB）

实时采集  主要组件flume

1. 富文本采集，主要使用fscrawler   ->   Es 
2. 协议采集  主要协议包括syslog + http/https + mqtt + restful_api
3. 普通文本采集
3. 消息队列采集  kafka -> kafka   

cdc同步

1. 使用flinkcdc作为引擎，需要对比maxwell    canal
2. 根据关系型数据的二进制日志分析数据的变化，写入到Es/hive中
3. 与实时运行原理相同

离线同步：

1. 底座使用ds,同步工具使用flinkx, 关于flinkx的插件自行开发，需要对比datax
2. ds组件二次开发，维护与迭代

实时分析场景**

实时采集+索引/主题管理+实时计算+实时运维+检索中心

1. 索引，主要是索引模板的管理，包括模板的增删改查，包括模板的分区，副本以及相关属性
2. 主题，主要是主题的增删改查，也涉及主题相关属性的设置
3. 通过拖拽的方式，来形成一条实时流，source（主要为kafka）
4. 数据处理过程，包括解析算子 + 数据分流
5. 数据目的（kafka + es + dipper + ck + oracle）   包含了很多自定义的sink算子
6. 同时包含了模型的调试，使用本地模式获取出流的输出，判断流是否正常

数仓建设方面

数据集成+宽表构建+离线计算+数仓查询    主要是kylin框架为基底，trino+ck为下推的引擎为辅的OLAP即席查询架构

安全

架构集成**

ranger 项目隔离      主要实现hive表权限的 + hdfs权限控制 + hbase权限控制

kafka使用scram权限机构体系构建，二次开发cmak，在原有的基础上对kafka集群进行监控（本身没有集成kerberos）

ES模板的控制不能完成，需要引入open distro实现，是一个Es的插件

元数据方面** 

atlas   （ES+ kafka+ hbase） 对于hive数仓的元数据信息监控与全量导入

数据质量 方面 ** 

griffin   不是很清楚 ，主要使用griffin引擎启用spark任务对数据质量进行定时监控

