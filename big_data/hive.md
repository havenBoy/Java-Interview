## HIVE
> 是一个构建在hadoop上的数据仓库工具，可将结构化的数据文件映射为表，并提供SQL查询功能  
> 用于查询的SQL语句会被映射为MapReduce任务执行，提交到hadoop上执行

- 特点 
  - 简单，容易上手  
  - 灵活性高，可以自定义udf与存储格式 
  - 可以用于超大数据量的查询，集群扩展方便
  - 统一的元数据管理，可以与presto/impala/sparksql等共享元数据
  - 执行的延迟较高，不适合做数据的实时处理，适合海量数据的离线处理  
- HIVE体系架构
  - command line shell 通过hive命令行的方式来操作数据
  - thift/jdbc  通过thift协议按照标准JDBC来操作数据  
  - meta_store 表名，表结构，字段名，字段类型等称为元数据，所有的元数据会存储在RDMS中，默认为derby,且元数据可被共享
  - HQL执行流程如下：  
    - 语法解析：Antlr定义出SQL的语法规则，完成语法与词法的分析，将SQL转化为AST Tree语法树  
    - 语义解析：遍历AST Tree 抽象出基本组成单元QueryBlock
    - 生成逻辑执行计划： 遍历Query Block,翻译为执行树operatorTree 
    - 优化逻辑执行计划： 逻辑层
    - 生成物理执行计划
    - 优化物理执行计划
- hive 数据模型
  - db: 在hive表现为hive.metastore.warehouse.dir下的文件夹
  - table  表
  - external table 数据存放
  - partition  分区
  - bucket 同一张表下哈希散列下的多个文件
- HIVE数据类型
  - 整型：tinyint,smallint,int,bigint
  - 布尔：boolean 
  - 浮点型：float double
  - 定点数：decimal(7,2) 用户自定义精度
  - 字符串：string
  - 日期类型：timestamp, date, timestamp with local timezone
  - 二进制类型：binary
- 常见DDL语句
  - 查看数据库  show databases;
  - 使用数据库  use database_name;
  - 新建数据库  create database xx if not exist database_name [comment 'xxx'] [location 'hdfs://path'] [with dbproperties]
  - 查看数据库信息  desc database [extended] database_name
  - 创建分区
  - 删除分区  会删除对应文件夹下的文件
  - 
- join
  - inner join
  - left join
  - right join
- json字符串
  - insert overwrite table select get_json_object(line, '$.id') as id from xxx

- 函数
  - round   取整
  - floor   去除小数，最大的整数
  - cell    向上取整
  - rand    随机数
  - abs     绝对值
  - 日期函数  year/month/day/weekofyear
  - 字符串函数  length/concat/lower/reverse/split
  - 类型转换   cast(value as TYPE)
  - 爆炸函数   lateral view explode(col)
  - udf/udtf/udaf  一进一出 (extends UDF)/输入一行输出多行()/多行输入一行输出（extends UDAF）
  - 窗口函数  
    - NTILE
    - ROW_NUMBER  按照
- 内部表与外部表的区别以及转换
  - 内部表也叫管理表，表的目录会放置在HDFS下
  - 外部表会在创建时在指定的路径下创建表的目录，如果指定location路径不存在，则与内部表一样。
  - 在删除表时，内外部表存在差异：  
    1. 内部表在删除时，会删除元数据信息以及hdfs上的目录以及数据  
    2. 外部表在删除时，不会删除hdfs上的目录以及数据，只会清除元数据信息
  - 转换： alter table  xxx set tblproperties ('EXTERNAL' = 'TRUE/FALSE')  //注意这里是大写
