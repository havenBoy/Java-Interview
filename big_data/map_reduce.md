## MapReduce
> 是一种可用于数据处理的编程或者计算模型 
> 它是将大型数据处理任务分解成多个、可以并行处理的，最后把任务的结果合并在一起合并得到最终的结果  
> 它的优势在于可以在部署在几千个廉价的机器上并行处理大规模集群  
#### 运行阶段

- ##### input_split
  
  1. hadoop将MapReduce输入数据划分为等长的小数据块，每一个小数据块称为分片，后续会为每一个
  
     split分片创建一个map任务，map任务处理逻辑由用户自定义来处理分片中的每条记录
  
  2. 数据库合理的分配近似于一个HDFS块的大小，默认为128M ，是一个block的大小
  
- ##### map  （包含shuffle阶段）
  
  0. map任务运行在数据块的节点上可以获取最佳性能，因为不会使用其他的网络资源
  1. map任务的输入是每个切片的按行读取，处理结束后，对key进行分区，写入缓存buffer，默认为Hash分区
  2. 每个map任务都会有一个环形缓冲区，map任务的输出会被称为中间键与中间值，此时发生一次快排
  3. 缓冲区在满了后，会将缓存区的内容写入临时文件，会存储在磁盘上，没有必要存储在hdfs上，因为不是最终结果
  4. 在map任务处理完毕后，会对所有的临时文件进行合并，产出最终的临时文件，等待reduce阶段拉取数据，此时发生归并排序
  
- ##### reduce （包含shuffle阶段）

  1. 拷贝阶段，将map阶段产生的文件拷贝过来
  2. 合并阶段，拷贝过来的文件会首先写入缓冲区，缓冲区达到溢出写入的阈值后，执行内存到磁盘的写入
  3. 磁盘写入后，会执行磁盘文件的合并，然后对合并的内容进行排序，排序为归并排序
  4. 对排序后的键值进行reduce过程，键值相等只需要调用一次reduce方法，最终将结果写入hdfs文件中

#### 运行过程描述

1. 读取hdfs上的输入分片，每一行会解析成一个key-value，输入可以为<1, hello world> <2, hello java>

2. 接收上阶段产生的结果进行处理，转换为新的key-value输出，输出<hello, 1> <world, 1><1, hello><1, java>

   每一个map任务都有一个环形内存缓冲区，输出的结果会首先输出到环形内存缓冲区，是由配置项

   mapreduce.task.io.sort.mb控制，由参数mapreduce.map.sort.spill.percent参数控制阈值，在达到阈值时

   会在本地启动线程将内容写入本地临时文件中，写出路径有参数mapreduce.cluster.local.dir参数控制

3. 对上述输出进行分区，默认一个分区，提供Partitioner接口，作用是决定输出数据会分配在那个reduce上处理

​      是根据key或者value值以及reduce数量来决定，默认是根据对key值进行hash再以reduce数量进行取模。

​      目的是平均reduce的处理能力，避免将所有数据分发到同一个reduce上；

#### shuffle的优化处理

- 增加环形缓冲区的大小，默认为100M，可设置为200M
- 设置溢出写的阈值，默认为80%，可以修改为90%
- map过程如果产生了较多的小文件时，会产生一个任务去合并小文件，文件的阈值可以调整，默认为10
- reduce端拷贝数据的线程数量，默认为5，可修改为10个
- reduce端内存的数据溢出写文件的百分比，默认为0.66

