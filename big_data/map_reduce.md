## MapReduce
> 是一种可用于数据处理的编程或者计算模型 
> 它是将大型数据处理任务分解成单个、可以并行处理的，最后把任务的结果合并在一起合并得到最终的结果  
> 它的优势在于可以在部署在几千个廉价的机器上并行处理大规模集群  
- #### 运行阶段
  
  - ##### input_split
    
    1. hadoop将MapReduce输入数据划分为等长的小数据块，每一个小数据块称为分片，后续会为每一个
    
       分片创建一个map任务，map任务处理逻辑由用户自定义来处理分片中的每条记录
    
    2. 数据库合理的分配近似于一个HDFS块的大小，默认为128M  
    
  - ##### map  
    
    0. map任务运行在数据块的节点上可以获取最佳性能，因为不会使用其他的网络资源
    
    1. map任务的输出会被称为中间键与中间值，后续会发送到reducer处理，结果会被写入磁盘
    2. 原因是，程序需要最终的结果，而非中间过程，如果是存储在hdfs上是没有必要的
    3. 如果由于在map将中间结果传送给reduce时出错时，会在另外一个节点上再次进行以构建map的中间结果
    
  - ##### shuffle 
    
    1.  需要保证reducer的输入是按照按键排序的，系统执行排序、将map的输出作为输入传给reduce的过程
    2. shuffle被属于不断优化和改进的一部分
    3. 
    
  - ##### reduce 
  
  - ##### output  
  
- #### 运行过程描述

  1. 读取hdfs上的输入分片，每一行会解析成一个key-value，输入可以为<1, hello world> <2, hello java>

  2. 接收上阶段产生的结果进行处理，转换为新的key-value输出，输出<hello, 1> <world, 1><1, hello><1, java>

  > 每一个map任务都有一个环形内存缓冲区，输出的结果会首先输出到环形内存缓冲区，是由配置项
  >
  > mapreduce.task.io.sort.mb控制，由参数mapreduce.map.sort.spill.percent参数控制阈值，在达到阈值时
  >
  > 会在本地启动线程将内容写入本地临时文件中，写出路径有参数mapreduce.cluster.local.dir参数控制

  3. 对上述输出进行分区，默认一个分区，提供Partitioner接口，作用是决定输出数据会分配在那个reduce上处理

  ​      是根据key或者value值以及reduce数量来决定，默认是根据对key值进行hash再以reduce数量进行取模。

  ​      目的是平均reduce的处理能力，避免将所有数据分发到同一个reduce上；

  ​      为了

- #### MapReduce任务运行机制

  - ##### 任务实体组成

    1、client   提交任务的客户端

    2、yarn   RM    负责协调集群上的计算资源

    3、yarn NM      负责启动与监控集群机器上的计算容器  container

    4、mapreduce AM  协调运行MR作业的任务

    5、hdfs  用来与其他实体间作业的共享

  - ##### 步骤描述

    - 客户端提交一个任务

