## flink

### 一、介绍

Apache Flink 是一个框架与分布式的处理引擎，用于对于无界与有界数据流进行状态转换。

### 二、flink快速上手

### 三、flink部署

- 从官方网站上下载关于flink的安装部署包，本次选择flink-1.13

### 四、flink运行时架

- ##### 作业管理器

  控制一个应用程序执行的主进程，是flink集群中任务管理与调度的核心

  **jobmaster**

  - 是最核心的组件，负责处理单独的作业
  - 在作业提交时，此对象会接受到需要提交的应用，一般是由客户端提交来的，包括了jar包，数据流图以及作业图
  - 会把
  
- ##### 作业提交流程

- ##### YARN集群

- ##### 数据流图

- ##### 并行度

  1. 一个算子的子任务个数称为并行度，一个流的并行度是由所有算子中最大的并行度，且流中的每个算子可以有不同的并行度
  2. 并行度的设置：可以在算子后调用setParallelism方法来设置，只对当前算子有效

- ##### 算子链

- ##### 任务与任务槽

  taskslots:  

  对于每一个taskmanager节点上可以并行执行的任务数，每个任务槽会拥有taskManager的一部分资源用来执行一个独立的子任务的

  设置：

  在配置文件中，使用参数taskmanager.numOfTaskSlots： 5   指定

- 

### 五、DataStream基础篇

- ##### 代码处理的基本构成

  1. 获取到执行环境（execution environment）
  2. 读取数据源（source）
  3. 基于数据的转换操作（transform）
  4. 定义计算结果的输出位置（sink）
  5. 触发程序的执行（execute）

- ##### 执行环境

  1. 需要获取SteamExecutionEnvironment对象，

     直接调用getExecutionEnvironment方法，如果程序是本地的，就返回一个本地环境，如果是使用jar包提交到集群环境，那么返回是集群执行环境，该方法会根据当前的运行方式来返回具体的执行环境

  2. createLocalEnvironment

     该方法返回一个本地执行环境，在调用时传入一个参数指定默认的并行度，如果不传入，则默认为本地的CPU核数

  3. createRemoteEnvironment

     该方法返回集群执行环境，需要在调用时指定JobManager的主机名与端口，并且指定需要运行的jar包

- ##### 执行模式

  1. streaming模式  -- 流处理模式

     用于处理实时的无界数据流，也是默认的执行模式

  2. batch模式  --批处理模式

     专门用于执行批处理的模式，即处理有界的数据

  3. automatic模式  -- 自动模式

     由程序来判断输入的数据为有界还是无界，自动选择模式

  4. 批处理模式的设置

     1. 通过命令行设置

        bin/flink run -Dexecution.runtime-mode=BATCH ...            推荐

     2. 通过代码配置

        env.setRuntimeMode(BATCH);              不推荐，认为是硬编码

- ##### 触发

  需要显示的调用执行环境的execute方法来触发程序的执行

- ##### 源算子

  1. 首要的任务是将数据读入进来

  2. 一般来是要env.addSource(...)来将输入数据读取进来，传入的参数需要实现SourceFunction，返回一个DataStreamSource对象
  3. 

### 六、窗口与水位线

### 七、处理函数

- 基本处理函数

  - 处理函数的功能与使用
  - ProcessFunction解析
    - 抽象类继承AbstractRich

  - 处理函数的分类

- 按键分区处理函数

- 窗口处理函数

- 应用案例

### 十、容错机制

- ##### 检查点

  - 检查点保存，又被称作一致性检查点

    1. 周期性的触发保存，不能时刻进行状态保存，会影响性能

    2. 保存的时间点

       当所有的任务都处理完一条相同的数据时，将其状态保存下来

       优点在于：要么是没有处理完毕，要么是处理完毕，类似于事务，只要等到source端重放数据，即可恢复到正常状态

  - 检查点恢复状态

    检查点的保存是有jobmanager触发的，故障的恢复也是需要jobmanager来参与

    1. 重启应用，此时应用内所有的状态都会清空
    2. 读取最近的检查点，重置状态
    3. 重放数据，比如kafka需要重新设置kafka读取的偏移量
    4. 继续处理数据

  - 检查点算法

    1. 检查点的分界线（checkpoint barrier）：一条流上的数据按照不同的检查点分开

    2. 标记是由jobmananger下发到源算子中的数据后，打上标签，每个平行任务只要处理完毕这个数据后，就开始打快照，

       之后等所有平行任务处理完毕之后，会进行一次快照的拼接，在标记后来的数据导致的状态的修改，则会包含在之后的检查点

    3. jobmanager中有一个检查点协调器（checkpoint  coordinator）,他会定期携带检查点ID值发出保存检测点的指令，首先source

       任务会将自己的偏移量保存起来，其次将带有检查点的分界线插入到数据流，当算子处理到这个分界线，就会对之前的状态进行

       快照

    4. 分布式快照算法：原则是，当上游任务向多个并行下游任务发送分解线时，需要将其广播出去，而多个上游任务向一个下游任务

       传递分界线时，需要在下游进行分界线的对齐操作，也就是所有的并行分区分界线都对齐时，才进行状态的保存

    5. 分区分界线不对齐，在11版本后支持

  - 检查点的配置

    1. 检查点存储备份间隔时间，单位毫秒

    2. 检查点存储位置设置：存储在作业管理器的堆内存、文件系统（手动指定hdfs路径，常用的）

    3. 其他高级参数

       - 检测点模式  checkPointMode

         分为精准一次（exactly-once）与至少一次（at-least-once）

       - 超时时间  checkPointTimeout

         用于指定检查点保存时间的超时时间，超时没有完成就会丢掉

       - 最小间隔时间  minPauseBetweenCheckPoints

         2次检查点出发时间的间隔，意味着即使已经达到触发时间，只要间隔时间不满足超时时间则不会进行触发

       - 最大并发检查点数量  maxConcurrentCheckpoints

         指定运行中的检查点最多的个数，参数minPauseBetweenCheckPoints与此参数有冲突，不能生效

       - 开启外部持久化存储  enableExternalizedCheckpoints    

         分为在作业失败时默认清理检查点数据，以及失败时不保存检查点数据

       - 检测点异常时是否影响任务的状态

         默认为true，如果设置为false，则任务会继续运行丢点检查点数据

       - 不对齐检查点

         该设置指定前提为检查点模式为精准一次，且并发度为1

  - 保存点（Savepoint）

    区别在于会多一些元数据，是由用户触发的，有计划的备份
    
    1. 创建保存点
       - bin/flink savepoint :jobId[:targetDirectory]
       - 同时可以指定保存点保存路径：state。savepoint.dir: hdfs://xxx
       - 在任务停止时，进行一次保存点的保存   bin/flink stop --savepointPath [:runArgs]
    2. 从保存点运行或者重启任务
       - bin/flink run -s :savepointPath [:runArgs]

- ##### 状态一致性

  - 最多一次    at_most_once   有可能不处理，会出现数据的丢失
  - 至少一次    at_least_once    至少处理一次，有的事件可能被处理多次，检查点设置后可以保证
  - 精确一次    exactly_once      不但数据没有丢失，而且只被处理一次

- ##### 端到端的消费一致性

  - 内部保证--开启checkpoint
  
  - source端  --可以重新设置数据的读取位置，这个是精确一次的最起码约束
  
  - sink端保证
  
    1. 原则：当故障恢复时，数据不会被重复写入外部系统中，
  
    2. 需要具备幂等写入、事务写入，二者选一即可
  
    3. 幂等写入：一个操作可以重复执行多次，但不改变结果，但会有一个后果：会有短暂的跳跃时刻
  
    4. 事务写入：事务的基本特征：原子性、一致性、隔离性以及持久性
  
       其中有2实现方式：
  
    - 预写日志
  
      先把结果数据保存起来
  
      进行检查点保存时同时将结果数据进行保存
  
      在收到检查点完成保存的通知后，将所有的结果一次性写入到外部系统
  
      优点：简单
  
      缺点：写入外部系统可能会保存失败，需要等待发送成功的确认消息，但如果确认消息发生故障时就需要回退
  
    - 两阶段提交
  
      当数据到来时，或者遇到检查点的分界线时，sink任务都会启动一个事务
  
      数据会写入外部系统中，但是由于事务暂无提交，那么外部也是看不到的
  
      当sink任务真正收到检查点完成的通知时，才会正式提交事务，而当中间发生故障时，事务就会回滚，写入到外部的数据会撤回
  
      但是对于外部系统有要求：
  
      - 外部系统需要支持事务
      - 在检查点的时间内，需要开启事务接受数据的写入
      - sink任务可在进程失败后恢复事务
      - 提交事务需要具有幂等性
  

### 十一、Table ApI 与 SQL

1. 一个简单的示例
2. 基本API
   - 程序架构
   - 创建表环境
   - 创建表
   - 表的查询
   - 表与流的转换
3. 流处理中的表

### 十二、flink cep 

##### 1.基本概念

  它是复杂事件处理的缩写，是flink用于处理复杂事件处理的库

- 首先定义出一个匹配的规则
- 将匹配的规则应用到输入的事件流中，检测是否满足复杂事件
- 对检测到的复杂事件，得到结果进行输出

##### 2.模式（pattern）

- 主要包括2个部分：
  1. 简单事件的特质
  2. 简单事件的组合关系

##### 3.应用场景

用于实时数据流，比如风险控制、用户的画像、运维监控

##### 4.快速上手

- 引入依赖
- 场景如：用户如果连续登陆失败三次，则应该输出报警信息

##### 5.模式API

- 个体模式：每个简单事件的匹配规则
- 量词：指定循环的次数，分为单例模式与循环模式
  1. oneOrMore    匹配一次事件出现一次或者多次
  2. times  匹配事件发生的次数
  3. times(from,to)   指定匹配事件出现的次数范围，最小为from，最大为to
  4. greedy      只能用在循环模式之后尽可能多的匹配事件出现的次数
  5. optional    使得当前的匹配模式成为可选的，意味着可以满足这个匹配的条件，也可不匹配
- 复杂条件
- 

