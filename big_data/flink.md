## flink

### 一、介绍

Apache Flink 是一个框架与分布式的处理引擎，用于对于无界与有界数据流进行状态转换。

### 二、flink快速上手

### 三、flink部署

- 从官方网站上下载关于flink的安装部署包，本次选择flink-1.13

### 四、flink运行时架

- ##### 作业管理器

  控制一个应用程序执行的主进程，是flink集群中任务管理与调度的核心

  **jobmaster**

  - 是最核心的组件，负责处理单独的作业
  - 在作业提交时，此对象会接受到需要提交的应用，一般是由客户端提交来的，包括了jar包，数据流图以及作业图
  - 会把
  
- ##### 作业提交流程

- ##### YARN集群

- ##### 数据流图

- ##### 并行度

  1. 一个算子的子任务个数称为并行度，一个流的并行度是由所有算子中最大的并行度，且流中的每个算子可以有不同的并行度
  2. 并行度的设置：可以在算子后调用setParallelism方法来设置，只对当前算子有效

- ##### 算子链

- ##### 任务与任务槽

  taskslots:  

  对于每一个taskmanager节点上可以并行执行的任务数，每个任务槽会拥有taskManager的一部分资源用来执行一个独立的子任务的

  设置：

  在配置文件中，使用参数taskmanager.numOfTaskSlots： 5   指定

- 

### 五、DataStream基础篇

- ##### 代码处理的基本构成

  1. 获取到执行环境（execution environment）
  2. 读取数据源（source）
  3. 基于数据的转换操作（transform）
  4. 定义计算结果的输出位置（sink）
  5. 触发程序的执行（execute）

- ##### 执行环境

  1. 需要获取SteamExecutionEnvironment对象，

     直接调用getExecutionEnvironment方法，如果程序是本地的，就返回一个本地环境，如果是使用jar包提交到集群环境，那么返回是集群执行环境，该方法会根据当前的运行方式来返回具体的执行环境

  2. createLocalEnvironment

     该方法返回一个本地执行环境，在调用时传入一个参数指定默认的并行度，如果不传入，则默认为本地的CPU核数

  3. createRemoteEnvironment

     该方法返回集群执行环境，需要在调用时指定JobManager的主机名与端口，并且指定需要运行的jar包

- ##### 执行模式

  1. streaming模式  -- 流处理模式

     用于处理实时的无界数据流，也是默认的执行模式

  2. batch模式  --批处理模式

     专门用于执行批处理的模式，即处理有界的数据

  3. automatic模式  -- 自动模式

     由程序来判断输入的数据为有界还是无界，自动选择模式

  4. 批处理模式的设置

     1. 通过命令行设置

        bin/flink run -Dexecution.runtime-mode=BATCH ...            推荐

     2. 通过代码配置

        env.setRuntimeMode(BATCH);              不推荐，认为是硬编码

- ##### 触发

  需要显示的调用执行环境的execute方法来触发程序的执行

- ##### 源算子

  1. 首要的任务是将数据读入进来

  2. 一般来是要env.addSource(...)来将输入数据读取进来，传入的参数需要实现SourceFunction，返回一个DataStreamSource对象
  3. 

### 六、窗口与水位线

### 七、处理函数

- 基本处理函数

  - 处理函数的功能与使用
  - ProcessFunction解析
    - 抽象类继承AbstractRich

  - 处理函数的分类

- 按键分区处理函数

- 窗口处理函数

- 应用案例

### 十、容错机制

- ##### 检查点

  - 检查点保存

  - 检查点恢复状态

  - 检查点算法

    在数据中加一些特殊的标记，表示在这个数据处理之后则需要做检查点的保存

    标记是由jobmananger下发到源算子中的数据，打上标签，每个平行任务只要处理完毕这个数据后，就开始打快照，之后等所有平行任务处理完毕之后，会进行一次快照的拼接

  - 检查点的配置

    检查点存储备份间隔时间

    检查点存储位置设置：作业管理器的堆内存、文件系统（手动指定hdfs路径，常用的）

  - 保存点（Savepoint）

    区别在于会多一些元数据，是由用户触发的，有计划的备份

- ##### 状态一致性

  - 最多一次    at_most_once   有可能不处理，会出现数据的丢失
  - 至少一次    at_least_once    至少处理一次，有的事件可能被处理多次，检查点设置后可以保证
  - 精确一次    exactly_once      不但数据没有丢失，而且只被处理一次

- ##### 端到端的消费一致性

  内部保证--开启checkpoint
  
  source端  --可以重新设置数据的读取位置
  
  sink端-- 当故障恢复时，数据不会被重复写入外部系统中，需要具备幂等写入、事务写入
  
  ### 十一、Table ApI 与 SQL
  
  1. 一个简单的示例
  2. 基本API
     - 程序架构
     - 创建表环境
     - 创建表
     - 表的查询
     - 表与流的转换
  3. 流处理中的表
  
  ### 十二、flink cep 
  
  ##### 1.基本概念
  
    它是复杂事件处理的缩写，是flink用于处理复杂事件处理的库
  
  - 首先定义出一个匹配的规则
  - 将匹配的规则应用到输入的事件流中，检测是否满足复杂事件
  - 对检测到的复杂事件，得到结果进行输出
  
  ##### 2.模式（pattern）
  
  - 主要包括2个部分：
    1. 简单事件的特质
    2. 简单事件的组合关系
  
  ##### 3.应用场景
  
  用于实时数据流，比如风险控制、用户的画像、运维监控
  
  ##### 4.快速上手
  
  - 引入依赖
  - 场景如：用户如果连续登陆失败三次，则应该输出报警信息
  
  ##### 5.模式API
  
  - 个体模式：每个简单事件的匹配规则
  - 量词：指定循环的次数，分为单例模式与循环模式
    1. oneOrMore    匹配一次事件出现一次或者多次
    2. times  匹配事件发生的次数
    3. times(from,to)   指定匹配事件出现的次数范围，最小为from，最大为to
    4. greedy      只能用在循环模式之后尽可能多的匹配事件出现的次数
    5. optional    使得当前的匹配模式成为可选的，意味着可以满足这个匹配的条件，也可不匹配
  - 复杂条件
  - 
  
  
